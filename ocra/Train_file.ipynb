{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import ctc_ops as ctc\n",
    "import os, codecs, cv2, sys, numpy as np\n",
    "from training import get_data as data_provider\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(img, low, high, extreme=0):\n",
    "    bright = np.amax(img)\n",
    "    dark = np.amin(img)\n",
    "    low_in = dark + (bright - dark) * low\n",
    "    high_in = dark + (bright - dark) * high\n",
    "    if extreme == 0:\n",
    "        img[img < low_in] = dark\n",
    "        img[img > high_in] = bright\n",
    "    else:\n",
    "        img[img < low_in] = 0\n",
    "        img[img > high_in] = 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifreverse1(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    top = img[0, :]\n",
    "    avg_edge = np.mean(top)\n",
    "    center_row = img[int(round(height / 2)), :]\n",
    "    avg_center = np.mean(center_row)\n",
    "    if avg_edge > avg_center:\n",
    "        img = 255 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifreverse2(img):\n",
    "    row = img[2, :]\n",
    "    large = np.sum(img == 255)\n",
    "    small = np.sum(img == 0)\n",
    "    if large > small:\n",
    "        img = 255 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifreverse3(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if img[(0, 0)] == 255 and img[(0, width - 1)] == 255 and img[(height - 1, 0)] == 255 and img[(height - 1, width - 1)] == 255:\n",
    "        img = 255 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    grayimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    grayimg = enhance(grayimg, 0.4, 0.6, 0)\n",
    "    grayimg = ifreverse1(grayimg)\n",
    "    grayimg = enhance(grayimg, 0.3, 0.7, 1)\n",
    "    grayimg = ifreverse2(grayimg)\n",
    "    grayimg = ifreverse3(grayimg)\n",
    "    dims = (int(round(48 * grayimg.shape[1] / grayimg.shape[0])), 48)\n",
    "    grayimg = cv2.resize(grayimg, dims)\n",
    "    grayimg = np.asarray(grayimg, dtype=np.uint32)\n",
    "    return grayimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2input(image):\n",
    "    dims = np.shape(image)\n",
    "    image = image[:, ::-1]\n",
    "    input = np.zeros(shape=[1, dims[1], 48, 1])\n",
    "    input[0, :dims[1], :, 0] = np.transpose(image[np.newaxis, :, :], (0, 2, 1))\n",
    "    len = np.zeros(shape=[1], dtype='int64')\n",
    "    len[0] = dims[1]\n",
    "    return (\n",
    "     input / 255.0, len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(sparse_tuple, row, dtype=np.int32):\n",
    "    optlist = []\n",
    "    cnt = 0\n",
    "    for pos in sparse_tuple[0]:\n",
    "        if pos[0] == row:\n",
    "            optlist.append(sparse_tuple[1][cnt])\n",
    "        cnt += 1\n",
    "\n",
    "    return optlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        image_height = 48\n",
    "        num_classes = 169\n",
    "        num_hidden_1 = 50\n",
    "        num_hidden_2 = 100\n",
    "        num_hidden_3 = 200\n",
    "        num_hidden_4 = 200\n",
    "        self.inputs0 = tf.placeholder(tf.float32, [None, None, image_height, 1], name='inputs')\n",
    "        inputs = tf.reshape(self.inputs0, [tf.shape(self.inputs0)[0], -1, image_height])\n",
    "        inputs = (inputs - 0.1) / 0.3\n",
    "        self.seq_len = tf.placeholder(tf.int32, [None], name='seq_len')\n",
    "        self.targets = tf.sparse_placeholder(tf.int32, name='targets')\n",
    "        cell_fn = tf.contrib.rnn.GRUCell\n",
    "        additional_cell_args = {}\n",
    "        rnn_fw_1 = cell_fn(num_hidden_1, **additional_cell_args)\n",
    "        rnn_bw_1 = cell_fn(num_hidden_1, **additional_cell_args)\n",
    "        rnn_fw_2 = cell_fn(num_hidden_2, **additional_cell_args)\n",
    "        rnn_bw_2 = cell_fn(num_hidden_2, **additional_cell_args)\n",
    "        rnn_fw_3 = cell_fn(num_hidden_3, **additional_cell_args)\n",
    "        rnn_bw_3 = cell_fn(num_hidden_3, **additional_cell_args)\n",
    "        rnn_fw_4 = cell_fn(num_hidden_4, **additional_cell_args)\n",
    "        rnn_bw_4 = cell_fn(num_hidden_4, **additional_cell_args)\n",
    "        with tf.variable_scope('layer1') as (vs1):\n",
    "            outputs_1, _ = tf.nn.bidirectional_dynamic_rnn(rnn_fw_1, rnn_bw_1, inputs, self.seq_len, dtype=tf.float32, parallel_iterations=1)\n",
    "            outputs_1 = tf.concat(axis=2, values=outputs_1)\n",
    "        with tf.variable_scope('layer2') as (vs2):\n",
    "            outputs_2, _ = tf.nn.bidirectional_dynamic_rnn(rnn_fw_2, rnn_bw_2, outputs_1, self.seq_len, dtype=tf.float32, parallel_iterations=1)\n",
    "            outputs_2 = tf.concat(axis=2, values=outputs_2)\n",
    "        with tf.variable_scope('layer3') as (vs3):\n",
    "            outputs_3, _ = tf.nn.bidirectional_dynamic_rnn(rnn_fw_3, rnn_bw_3, outputs_2, self.seq_len, dtype=tf.float32, parallel_iterations=1)\n",
    "            outputs_3 = tf.concat(axis=2, values=outputs_3)\n",
    "        with tf.variable_scope('layer4') as (vs4):\n",
    "            outputs, _ = tf.nn.bidirectional_dynamic_rnn(rnn_fw_4, rnn_bw_4, outputs_3, self.seq_len, dtype=tf.float32, parallel_iterations=1)\n",
    "            outputs = tf.concat(axis=2, values=outputs)\n",
    "        shape = tf.shape(inputs)\n",
    "        batch_s, max_timesteps = shape[0], shape[1]\n",
    "        outputs = tf.reshape(outputs, [-1, num_hidden_4 * 2])\n",
    "        W = tf.Variable(tf.truncated_normal([num_hidden_4 * 2, num_classes], stddev=0.01), name='ctc_weights')\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name='ctc_bias')\n",
    "        logits = tf.matmul(outputs, W) + b\n",
    "        logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "        logits = tf.transpose(logits, (1, 0, 2))\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.loss = tf.nn.ctc_loss(labels=self.targets, inputs=logits, sequence_length=self.seq_len)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(self.loss)\n",
    "        \n",
    "        self.decoded, log_prob = ctc.ctc_beam_search_decoder(logits, tf.cast(self.seq_len, dtype='int32'))\n",
    "        self.err = tf.reduce_sum(tf.edit_distance(tf.cast(self.decoded[0], tf.int32), self.targets, normalize=False))\n",
    "        self.optimizer = tf.train.AdamOptimizer(0.0001).minimize(self.cost)\n",
    "        self.saver = tf.train.Saver(max_to_keep=0)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(session, gpu_id=-1):\n",
    "    if gpu_id == -1:\n",
    "        xpu = '/cpu:0'\n",
    "    else:\n",
    "        xpu = '/gpu:' + str(gpu_id)\n",
    "    with tf.device(xpu):\n",
    "        model = Model()\n",
    "    tf.global_variables_initializer().run()\n",
    "    model_dir = './model/'\n",
    "    names = os.listdir(model_dir)\n",
    "    model_file = 'model.ckpt'\n",
    "    model.saver.restore(session, model_dir + model_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recog(img_path, model, session):\n",
    "    dict = './look_up.txt'\n",
    "    f = codecs.open(dict, 'r', 'utf-8')\n",
    "    look_up_lines = f.readlines()\n",
    "    f.close()\n",
    "    image = preprocess(img_path)\n",
    "    img, len = img2input(image)\n",
    "    feed = {model.inputs0: img, model.seq_len: len}\n",
    "    decoded_Array = session.run(model.decoded[0], feed_dict=feed)\n",
    "    decoded_str = get_row(decoded_Array, 0)\n",
    "    lats = []\n",
    "    for cnt in decoded_str:\n",
    "        look_up_line = look_up_lines[cnt]\n",
    "        lat = look_up_line.split('*')[0]\n",
    "        lats.append(lat)\n",
    "\n",
    "    return lats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network():\n",
    "\n",
    "    model = Model ()\n",
    "    data=[]\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "    config.allow_soft_placement = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        data_generator = data_provider.get_batch(num_workers=4)\n",
    "\n",
    "        start = time.time()\n",
    "        for epoch in range(5000):\n",
    "            epoch_loss = 0\n",
    "\n",
    "            data = next(data_generator)\n",
    "            output = tf.convert_to_tensor(data[2] , dtype=tf.int32)\n",
    "            print (output)\n",
    "            #output1=tf.map_fn(lambda x: (x, x),output)\n",
    "\n",
    "            print (output)   \n",
    "            c,_ = sess.run([model.cost, model.optimizer], feed_dict={model.inputs0:data[0], model.seq_len:data[1],model.targets:output})\n",
    "\n",
    "            epoch_loss += c\n",
    "\n",
    "                \n",
    "\n",
    "            print('Epoch', epoch, 'completed out of', epochs, 'loss:', epoch_loss)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                avg_time_per_step = (time.time() - start) / 10\n",
    "                start = time.time()\n",
    "                print('avg_time_per_step', avg_time_per_step )\n",
    "            if epoch % 10 == 0:\n",
    "                filename = ('ctpn_{:d}'.format(epoch + 1) + '.ckpt')\n",
    "                filename = os.path.join(\"./model/\", filename)\n",
    "                model.saver.saver(sess,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/khalyl/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/khalyl/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "Find 7073 images\n",
      "Find 7073 images\n",
      "Find 7073 images\n",
      "Find 7073 images\n",
      "7073 training images in /media/khalyl/b19f6211-f6a7-443d-8a50-5c247986129e/khalyl/Desktop/image_recog/text-detection-ctpn-banjin-dev/ocr/training/data/\n",
      "7073 training images in /media/khalyl/b19f6211-f6a7-443d-8a50-5c247986129e/khalyl/Desktop/image_recog/text-detection-ctpn-banjin-dev/ocr/training/data/\n",
      "7073 training images in /media/khalyl/b19f6211-f6a7-443d-8a50-5c247986129e/khalyl/Desktop/image_recog/text-detection-ctpn-banjin-dev/ocr/training/data/\n",
      "7073 training images in /media/khalyl/b19f6211-f6a7-443d-8a50-5c247986129e/khalyl/Desktop/image_recog/text-detection-ctpn-banjin-dev/ocr/training/data/\n",
      "'Digit_'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Digit_'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Xaa_'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Digit_'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "Tensor(\"Const_2:0\", shape=(16,), dtype=int32)\n",
      "Tensor(\"Const_2:0\", shape=(16,), dtype=int32)\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n",
      "'Alif_I'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7dc5a6b3f4b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-ca08aa1884e0>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1035\u001b[0m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dict_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_feed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             subfeed_t = self.graph.as_graph_element(\n",
      "\u001b[0;32m~/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_feed_fn\u001b[0;34m(feed, feed_val)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_REGISTERED_EXPANSIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mfeed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m       raise TypeError('Feed argument %r has invalid type %r' % (feed,\n\u001b[1;32m   1019\u001b[0m                                                                 type(feed)))\n",
      "\u001b[0;32m~/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(feed, feed_val)\u001b[0m\n\u001b[1;32m    109\u001b[0m          lambda fetched_vals: sparse_tensor.SparseTensorValue(*fetched_vals)),\n\u001b[1;32m    110\u001b[0m      lambda feed, feed_val: list(zip(\n\u001b[0;32m--> 111\u001b[0;31m          [feed.indices, feed.values, feed.dense_shape], feed_val)),\n\u001b[0m\u001b[1;32m    112\u001b[0m      lambda feed: [feed.indices, feed.values, feed.dense_shape]),\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# IndexedSlices are fetched as IndexedSlicesValues. They can be fed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rcnnenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       raise TypeError(\n\u001b[0;32m--> 431\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    433\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Alif_I'\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "'Alif_I'\n",
      "''\n",
      "''\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
